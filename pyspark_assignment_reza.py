# -*- coding: utf-8 -*-
"""pyspark_assignment_reza.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dWZw_FGS51bDlTmBL5oSuKdzNXdVvePJ

# Install Library
"""

# Install library yang dibutuhkan
# !pip install plotly
# !pip install pyspark
# !pip install -U kaleido

# Build spark session
from pyspark.sql import SparkSession

spark_session = (
    SparkSession.builder.appName("pyspark_assignment").master("local").getOrCreate()
)

"""# Dataframe cleaning and transformation

Membaca data csv
"""

# Membaca tabel customer flight activity menggunakan spark
dfr_cflightActivity = spark_session.read.csv(
    "customer_flight_activity.csv", header=True
)
dfr_cflightActivity.show(5)

# Membaca tabel customer loyalty history menggunakan spark
dfr_cloyaltyHistory = spark_session.read.csv(
    "customer_loyalty_history.csv", header=True
)
dfr_cloyaltyHistory.show(5)

# Membaca tabel calendar menggunakan spark
dfr_calendar = spark_session.read.csv("calendar.csv", header=True)
dfr_calendar.show(5)

"""Cek struktur schema masing-masing tabel"""

# Cek struktur tabel
dfr_cflightActivity.printSchema()
dfr_cloyaltyHistory.printSchema()
dfr_calendar.printSchema()

"""Buat schema masing-masing tabel"""

from pyspark.sql.types import *

# Membuat schema untuk tabel cflightActivity
Schema_cflightActivity = StructType(
    [
        StructField("_c0", IntegerType(), True),
        StructField("loyalty_number", IntegerType(), True),
        StructField("year", IntegerType(), True),
        StructField("month", IntegerType(), True),
        StructField("total_flights", IntegerType(), True),
        StructField("distance", IntegerType(), True),
        StructField("points_accumulated", DoubleType(), True),
        StructField("points_redeemed", IntegerType(), True),
        StructField("dollar_cost_points_redeemed", DoubleType(), True),
    ]
)

# Membuat schema untuk tabel cloyaltyHistory
Schema_cloyaltyHistory = StructType(
    [
        StructField("_c0", IntegerType(), True),
        StructField("loyalty_number", IntegerType(), True),
        StructField("country", StringType(), True),
        StructField("province", StringType(), True),
        StructField("city", StringType(), True),
        StructField("postal_code", StringType(), True),
        StructField("gender", StringType(), True),
        StructField("education", StringType(), True),
        StructField("salary", DoubleType(), True),
        StructField("marital_status", StringType(), True),
        StructField("loyalty_card", StringType(), True),
        StructField("customer_lifetime_value", IntegerType(), True),
        StructField("enrollment_type", StringType(), True),
        StructField("enrollment_year", IntegerType(), True),
        StructField("enrollment_month", IntegerType(), True),
        StructField("cancellation_year", IntegerType(), True),
        StructField("cancellation_month", IntegerType(), True),
    ]
)

# Membuat schema untuk tabel calendar
Schema_calendar = StructType(
    [
        StructField("_c0", IntegerType(), True),
        StructField("date", DateType(), True),
        StructField("start_of_the_year", StringType(), True),
        StructField("start_of_the_quarter", StringType(), True),
        StructField("start_of_the_month", StringType(), True),
    ]
)

# Membaca tabel menggunakan schema yang telah dibuat sebelumnya.
dfr_cflightActivity = spark_session.read.csv(
    "customer_flight_activity.csv", header=True, schema=Schema_cflightActivity
)
dfr_cloyaltyHistory = spark_session.read.csv(
    "customer_loyalty_history.csv", header=True, schema=Schema_cloyaltyHistory
)
dfr_calendar = spark_session.read.csv(
    "calendar.csv", header=True, schema=Schema_calendar
)

# Melihat 5 baris data masing-masing tabel
dfr_cflightActivity.show(5)
dfr_cloyaltyHistory.show(5)
dfr_calendar.show(5)

"""Kolom masih berantakan, perlu menghilangkan kolom _c0 dari data"""

# Drop kolom _c0 dari masing-masing tabel
df_cflightActivity = dfr_cflightActivity.drop("_c0")
df_cloyaltyHistory = dfr_cloyaltyHistory.drop("_c0")
df_calendar = dfr_calendar.drop("_c0")

df_cflightActivity.show(5)
df_cloyaltyHistory.show(5)
df_calendar.show(5)

"""Handle null values"""

# Mengganti nilai NULL pada tabel cloyaltyHistory menjadi 0
df_cloyaltyHistory = df_cloyaltyHistory.na.fill(
    {
        "salary": 0,
        "customer_lifetime_value": 0,
        "enrollment_year": 0,
        "enrollment_month": 0,
        "cancellation_year": 0,
        "cancellation_month": 0,
    }
)

df_cloyaltyHistory.show(5)

"""# Analisis Dataset

import library
"""

# Import library
import plotly.express as px
import pandas as pd

"""mendefinisikan tabel sementara"""

# Cast dataframe menjadi tabel sementara untuk nantinya bisa dilakukan query sql
df_cloyaltyHistory.createOrReplaceTempView("cloyaltyhistory")
df_cflightActivity.createOrReplaceTempView("cflightactivity")
df_calendar.createOrReplaceTempView("calendar")

# Testing apakah query dapat berjalan sesuai dengan tabel yang telah dibuat
spark_session.sql("SELECT * FROM cloyaltyhistory LIMIT 5").show()
spark_session.sql("SELECT * FROM cflightactivity LIMIT 5").show()
spark_session.sql("SELECT * FROM calendar LIMIT 5").show()

"""Analisis Pertama
*   Rata-rata gaji tiap loyalty card




"""

# Membuat data frame untuk menyimpan hasil query rata-rata gaji tiap loyalty card
df_rata2gaji = spark_session.sql(
    "SELECT loyalty_card, AVG(salary) AS rata_rata_gaji FROM cloyaltyhistory GROUP BY loyalty_card"
)
df_rata2gaji.show()

# Mengubah dataframe ke pandas untuk bisa divisualisasi
pandas_df_rata2gaji = df_rata2gaji.toPandas()

# Memvisualisasi data berdasarkan loyalty_card terhadap rata-rata gaji
fug = px.bar(
    pandas_df_rata2gaji,
    x="loyalty_card",
    y="rata_rata_gaji",
    title="Rata-rata gaji tiap loyalty card",
)
fug.show()

# Mengambil gambar visualisasi menggunakan kaleido
fug.write_image("rata2_gaji_tiap_loyaltycard.png")

"""Analisis Kedua

*   Perbandingan total point redeemed antara tahun 2018 dan 2017




"""

# Membuat dataframe untuk menyimpan hasil query perbandingan total point redeemed
df_pointredeem = spark_session.sql(
    "SELECT year, SUM(points_redeemed) AS total_point_redeemed FROM cflightactivity GROUP BY year"
)
df_pointredeem.show()

# Mengubah dataframe ke pandas untuk bisa divisualisasi
pandas_df_pointredeem = df_pointredeem.toPandas()

# Memvisualisasi data perbandingan point redeemed tiap tahun.
fig = px.bar(
    pandas_df_pointredeem,
    x="year",
    y="total_point_redeemed",
    title="Pergerakan point redeemed tiap tahun",
)
fig.show()

# Mengambil gambar visualisasi menggunakan kaleido
fig.write_image("perbandingan_tahun_point_redeemed.png")

"""Analisis Ketiga

*   Provinsi yang memiliki urutan jumlah penerbangan tertinggi di tahun 2018


"""

# Membuat dataframe untuk menyimpan hasil query urutan provinsi yang memiliki jumlah penerbangan tertinggi di tahun 2018
df_penerbangan_provinsi = spark_session.sql(
    """SELECT l.province, SUM(f.total_flights) AS jumlah_penerbangan \
 FROM cloyaltyhistory l INNER JOIN cflightactivity f ON l.loyalty_number = f.loyalty_number \
 WHERE f.year = 2018 GROUP BY province ORDER BY jumlah_penerbangan DESC"""
)
df_penerbangan_provinsi.show()

# Mengubah dataframe ke pandas untuk bisa divisualisasi
pandas_df_penerbangan_provinsi = df_penerbangan_provinsi.toPandas()

# Memvisualisasikan urutan provinsi yang memiliki jumlah penerbangan tertinggi di tahun 2018
fig = px.bar(
    pandas_df_penerbangan_provinsi,
    x="province",
    y="jumlah_penerbangan",
    title="Provinsi dengan jumlah penerbangan tertinggi di tahun 2018",
)
fig.show()

# Mengambil gambar visualisasi menggunakan kaleido
fig.write_image("urutan_provinsi_jumlahpenerbangan.png")

"""Analisis keempat
*   Urutan penerbangan tertinggi di kota yang berada pada provinsi ontario


"""

# Membuat dataframe untuk menyimpan hasil query urutan kota mana yang memiliki jumlah penerbangan tertinggi di provinsi ontario
df_penerbangan_city = spark_session.sql(
    """SELECT l.city, SUM(f.total_flights) AS jumlah_penerbangan \
 FROM cloyaltyhistory l INNER JOIN cflightactivity f ON l.loyalty_number = f.loyalty_number \
 WHERE l.province = "Ontario" GROUP BY city ORDER BY jumlah_penerbangan DESC"""
)
df_penerbangan_city.show()

# Mengubah dataframe ke pandas untuk bisa divisualisasi
pandas_df_penerbangan_city = df_penerbangan_city.toPandas()

# Memvisualisasikan urutan kota yang memiliki jumlah penerbangan tertinggi di provinsi ontario
fig = px.bar(
    pandas_df_penerbangan_city,
    x="city",
    y="jumlah_penerbangan",
    title="Kota dengan jumlah penerbangan tertinggi di provinsi Ontario",
)
fig.show()

# Mengambil gambar visualisasi menggunakan kaleido
fig.write_image("urutan_kota_diontario_jumlahpenerbangan.png")

"""Analisis kelima
*   Perbandingan jumlah penerbangan di quartal 1 hingga quartal 4 di tahun 2018


"""

# Membuat dataframe untuk menyimpan hasil query perbandingan jumlah penerbangan tiap quartal di tahun 2018
df_perbandingan_quartal = spark_session.sql(
    """
    WITH quartal_pertama AS(
      SELECT
       SUM(f.total_flights) AS jumlah_penerbangan
      FROM cflightactivity f
      INNER JOIN calendar c ON f.year = year(c.date) AND f.month = month(c.date)
      WHERE c.start_of_the_quarter >= '2018-01-01'
       AND c.start_of_the_quarter < '2018-04-01'
    ),
    quartal_kedua AS(
      SELECT
       SUM(f.total_flights) AS jumlah_penerbangan
      FROM cflightactivity f
      INNER JOIN calendar c ON f.year = year(c.date) AND f.month = month(c.date)
      WHERE c.start_of_the_quarter >= '2018-04-01'
       AND c.start_of_the_quarter < '2018-07-01'
    ),
    quartal_ketiga AS(
      SELECT
       SUM(f.total_flights) AS jumlah_penerbangan
      FROM cflightactivity f
      INNER JOIN calendar c ON f.year = year(c.date) AND f.month = month(c.date)
      WHERE c.start_of_the_quarter >= '2018-07-01'
        AND c.start_of_the_quarter < '2018-10-01'
    ),
    quartal_keempat AS(
      SELECT
       SUM(f.total_flights) AS jumlah_penerbangan
      FROM cflightactivity f
      INNER JOIN calendar c ON f.year = year(c.date) AND f.month = month(c.date)
      WHERE c.start_of_the_quarter >= '2018-10-01'
        AND c.start_of_the_quarter < '2019-01-01'
    )
    SELECT
     'quartal_pertama' AS quartal,
     jumlah_penerbangan
    FROM quartal_pertama
    UNION ALL
    SELECT
     'quartal_kedua' AS quartal,
     jumlah_penerbangan
    FROM quartal_kedua
    UNION ALL
    SELECT
     'quartal_ketiga' AS quartal,
     jumlah_penerbangan
    FROM quartal_ketiga
    UNION ALL
    SELECT
     'quartal_keempat' AS quartal,
     jumlah_penerbangan
    FROM quartal_keempat
    """
)
df_perbandingan_quartal.show()

# Mengubah dataframe ke pandas untuk bisa divisualisasi
pandas_df_perbandingan_quartal = df_perbandingan_quartal.toPandas()

# Memvisualisasikan perbandingan Jumlah Penerbangan di tiap quartal 2018
fig = px.bar(
    pandas_df_perbandingan_quartal,
    x="quartal",
    y="jumlah_penerbangan",
    title="Perbandingan Jumlah Penerbangan di Tiap Quartal 2018",
)
fig.show()

# Mengambil gambar visualisasi menggunakan kaleido
fig.write_image("perbandingan_penerbangan_tiapquartal_2018.png")

"""Analisis Keenam

*   Provinsi dengan urutan provinsi dengan jumlah penerbangan tertinggi di quartal_ketiga 2018


"""

# Membuat dataframe untuk menyimpan hasil query urutan provinsi dengan jumlah penerbangan tertinggi di quartal ketiga tahun 2018
df_provinsi_quartal = spark_session.sql(
    """
    SELECT l.province, SUM(f.total_flights) AS jumlah_penerbangan \
    FROM cloyaltyhistory l
    INNER JOIN cflightactivity f
     ON l.loyalty_number = f.loyalty_number
    INNER JOIN calendar c
     ON month(c.date) = f.month AND year(c.date) = f.year
    WHERE c.start_of_the_quarter >= '2018-07-01'
     AND c.start_of_the_quarter < '2018-10-01'
    GROUP BY province
    ORDER BY jumlah_penerbangan DESC
    """
)
df_provinsi_quartal.show()

# Mengubah dataframe ke pandas untuk bisa divisualisasi
pandas_df_provinsi_quartal = df_provinsi_quartal.toPandas()

# Memvisualisasikan perbandingan urutan provinsi yang memiliki jumlah penerbangan tertinggi di quartal ketiga 2018
fig = px.bar(
    pandas_df_provinsi_quartal,
    x="province",
    y="jumlah_penerbangan",
    title="Provinsi dengan jumlah penerbangan tertinggi di Quartal Ketiga 2018",
)
fig.show()

# Mengambil gambar visualisasi menggunakan kaleido
fig.write_image("urutan_penerbangan_provinsi_quartal3_2018.png")

"""# Load analysis result into csv using spark"""

# Mengubah hasil read query menjadi csv file
df_rata2gaji.write.csv("rata2gaji.csv", header=True)
df_pointredeem.write.csv("pointredeem.csv", header=True)
df_penerbangan_provinsi.write.csv("penerbangan_provinsi.csv", header=True)
df_penerbangan_city.write.csv("penerbangan_city.csv", header=True)
df_perbandingan_quartal.write.csv("perbandingan_quartal.csv", header=True)
df_provinsi_quartal.write.csv("provinsi_quartal.csv", header=True)
